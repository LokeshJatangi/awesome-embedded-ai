---
layout: default
---

# 嵌入式AI简报 (2020-03-30)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：近来比较大的新闻，可能就要数国内各种框架开源，来自清华大学计算机图形学组的Jittor、旷视动态图和静态图合一且训练推理一体的MegEngine（ARM部分6月开源）、华为的MindSpore，还有今年将要开源的OneFlow；[商汤科技被曝折戟IPO：未形成核心技术壁垒，九轮融资后上市未卜](https://mp.weixin.qq.com/s/p2HXLs885AgrImuHcRLY0A)，[女黑客以含有Navi和Arden GPU的源码勒索AMD1亿赎金](https://mp.weixin.qq.com/s/sNEPalEUgg0iC_Ktc21e_Q)，[联发科技也发文大力**PRML**自家天玑系列5G芯片搭载的AI处理器APU3.0](https://mp.weixin.qq.com/s/toQvejvnmb0uTXJPtNAgow)。[三星目前正与超微半导体公司（AMD）合作发新的定制GPU解决方案，把Radeon GPU技术应用到Exynos 芯片中](https://mp.weixin.qq.com/s/Fs0py4zuTH8_wZ4qSYWoeg)。但是，也Exynos 990与骁龙865在CPU/GPU性能上差距明显有[数万网友联名请愿：要求三星停用Exynos处理器](https://mp.weixin.qq.com/s/6dcZUbjmaN5s4vEAN8FR0Q)。


## 业界新闻

- [搭载5G SOC麒麟820的荣耀30S即将发布 | 电脑爱好者](https://mp.weixin.qq.com/s/S4UGWqEioWvW3b4FHsddsQ)  
摘要：一颗SoC的性能几何，在很大程度上取决于制程工艺，工艺越先进，SoC就能更长时间满血运行，发热量还低，在同级别SoC中容易占据优势。
据悉，麒麟820将基于台积电最成熟的7nm工艺制造，采用Cortex-A76架构的CPU，以及Mali-G77架构的GPU。同时，麒麟820还将集成华为自研的最新达芬奇架构NPU，ISP性能更强。  
Cortex-A76和Mali-G77的组合强吗？答案是还凑合。Cortex-A76是ARM在2018年发布的CPU核心（同期GPU为Mali-G76），而Mali-G77则是ARM在2019年发布的GPU核心（同期CPU为Cortex-A77），它们的组合属于跨代的混搭，没能用A77+G77的黄金搭档是麒麟820的最大遗憾之处。  
在中高端5G SoC中，目前只有联发科天玑1000L采用了A77+G77的组合，Exyno 980是A77+G76，联发科还未上市的天玑800则是A76+G77，后者和麒麟820的思路一样。  
- []()

mindspore: MindSpore is a new open source deep learning training/inference framework that could be used for mobile, edge and cloud scenarios.
https://gitee.com/mindspore/mindspore

## 论文

- [CVPR2020] [IR-Net：信息保留的二值神经网络，落地性能和实用性俱佳 | 机器学习研究组](https://mp.weixin.qq.com/s/TaMSQulDR9zeFOX13qn0_g)  
摘要：不同于以往二值神经网络大多关注量化误差方面，本文首次从统一信息的角度研究了二值网络的前向和后向传播过程，为网络二值化机制的研究提供了全新视角。
本文首次从信息流的角度研究了网络二值化，提出了一种新的信息保持网络（IR-Net）：(1)在前向传播中引入了一种称为Libra参数二值化（Libra-PB）的平衡标准化量化方法，最大化量化参数的信息熵和最小化量化误差；(2) 在反向传播中采用误差衰减估计器（EDE）来计算梯度，保证训练开始时的充分更新和训练结束时的精确梯度。  
IR-Net提供了一个全新的角度来理解二值神经网络是如何运行的，并且具有很好的通用性，可以在标准的网络训练流程中进行优化。作者使用CIFAR-10和ImageNet数据集上的图像分类任务来评估提出的IR-Net，同时借助开源二值化推理库daBNN进行了部署效率验证。
在ARM设备上进行了先进二值化算法效率验证，显示了IR-Net部署时的优异性能和极高的实用性，有助于解决工业界关注的神经网络二值化落地的核心问题。

## 开源项目

> 注：每条内容前缀为github地址的仓库拥有者和仓库名`<repo_owner>/<repo_name>`。


jpinedaa/Voice-ML: MobileNet trained with VoxCeleb dataset and used for voice verification
https://github.com/jpinedaa/Voice-ML

- [xiangweizeng/mobile-lpr: Mobile-LPR 是一个面向移动端的准商业级车牌识别库](https://github.com/xiangweizeng/mobile-lpr)
摘要：以NCNN作为推理后端，使用DNN作为算法核心，支持多种车牌检测算法，支持车牌识别和车牌颜色识别。特点如下:  
  1. 超轻量，核心库只依赖NCNN，并且对模型量化进行支持；  
  2. 多检测，支持SSD,MTCNN,LFFD等目标检测算法；  
  3. 精度高，LFFD目标检测在CCPD检测AP达到98.9，车牌识别达到99.95%， 综合识别率超过99%；  
  4. 易使用，只需要10行代码即可完成车牌识别；  
  5. 易扩展，可快速扩展各类检测算法。  
- [xiangweizeng/darknet2ncnn: Darknet2ncnn converts the darknet model to the ncnn model](https://github.com/xiangweizeng/darknet2ncnn)  
摘要：Darknet2ncnn converts the darknet model to the ncnn model, enabling rapid deployment of the darknet network model on the mobile device.  
Gitee : https://gitee.com/damone/darknet2ncnn  
  1. Support network layers except local/xor conv, rnn, lstm, gru, crnn and iseg；  
  2. Added all activation operations not directly supported by ncnn, implemented in the layer DarknetActivation；  
  3. Added the implementation of the shortcut layer, implemented in the layer DarknetShortCut；  
  4. Added yolo layer and detection layer implementation, support YOLOV1 and YOLOV3；  
  5. Provides a converted model verification tool, convert_verify, which supports checking the calculation output of each layer of the network, supports convolutional layer parameter checking, and facilitates rapid positioning of problems in model conversion.  
- [wuba/dl_inference：通用深度学习推理服务 | 58技术](https://mp.weixin.qq.com/s/GsTGBnP2t-8G8RbvG8SeVQ)  
摘要：58的通用深度学习推理服务，可在生产环境中快速上线由TensorFlow、PyTorch框架训练出的深度学习模型。  
dl_inference是58同城推出的通用深度学习推理服务，可在生产环境中快速上线由TensorFlow、PyTorch框架训练出的深度学习模型。dl_inference当前支持TensorFlow和PyTorch模型，提供GPU和CPU两种部署方式，并且实现了模型多节点部署时的负载均衡策略，支持线上海量推理请求，该服务支撑了58同城各AI场景下日均超过10亿次的线上推理请求。dl_inference具备如下特点：  
  1. 简化深度学习模型的推理服务部署；
  2. 支持模型多节点部署并实现负载均衡策略；
  3. 提供统一的RPC服务调用接口；
  4. 提供GPU和CPU两种部署方式；
  5. PyTorch模型支持推理前后数据处理，开放模型调用。  
- [PaddleSeg图像分割库再添新武器，新增压缩部署方案FLOPs降低51% | 飞桨PaddlePaddle](https://mp.weixin.qq.com/s/W-cSWlw_qdEkwoEtC5wsPQ)  
摘要：在某些场景中，语义分割模型在实际部署时，可能会由于耗时、体积等多方面因素导致模型无法满足要求。此时模型压缩通常是解决内存占用和速度问题的有效手段。PaddleSlim为PaddleSeg提供了多种分割模型的压缩方案，以L1 Pruning裁剪方案为例，该方案通过裁剪掉卷积核来减小模型体积并降低模型计算复杂度。  


- [有效提高视觉模型精度：EfficientNet-Lite 发布 | TensorFlow](https://mp.weixin.qq.com/s/sFPSen3f9d1WvO0ggdyHMA)  
地址：https://github.com/google/automl/tree/master/efficientdet  
摘要：2019 年 5 月，Google 发布了一系列名为 EfficientNet 的图像分类模型，此类模型在降低一个数量级的参数和算力消耗的情况下，实现了最前沿 (SOTA) 的精度。如果 EfficientNet 可以在边缘设备上运行，则将为计算资源受限的移动和 IoT 设备开拓全新的应用场景。  
今天推出 EfficientNet-Lite (GitHub，TFHub)，该模型在 TensorFlow Lite 上已针对 CPU、GPU 和 EdgeTPU 进行性能优化。EfficientNet-Lite 让边缘设备也能利用 EfficientNet 的强大性能，并提供五个不同版本，让用户能够按照自己的需求从低延迟/小模型 (EfficientNet-Lite0) 到高精度 (EfficientNet-Lite4) 之间进行灵活选择。  
其中计算量最大的版本，纯整型量化(Integer-Only Quantized EfficientNet-Lite4) 的 EfficientNet-Lite4，在 ImageNet 上可达到 80.4％ 的 Top-1 精度，同时可实时运行在 Pixel 4 CPU （30 毫秒/图像）上。  
除了量化模型外，为了解决异构硬件问题，我们对原本的 EfficientNets 进行了如下改进：  
  1. 删除 Squeeze-and-Excitation 网络，因在这类设备上支持欠佳；  
  2. 用 RELU6 替代所有 swish 激活函数，从而显著提升训练后量化的质量；  
  3. 放大模型时固定住其 stem 与 head 模块，以减少缩放后模型的大小与计算量。  


## 博文

2020 TensorFlow Dev Summit 什么让你印象最深刻？
https://www.zhihu.com/question/378610205



- [详细记录超轻量中文OCR LSTM模型ncnn实现 | 知乎](https://zhuanlan.zhihu.com/p/113338890)  
摘要：前阵子ouyanghuiyu的OCR一条龙项目用到了LSTM，效果不错。本文作者用作实验模型把LSTM搞出来提升识别准确性，一方面算是填上ncnn LSTM的坑。ncnn没有batch维度，跑LSTM模型需要一些特殊手法，作者把LSTM和OCR在ncnn上的实现过程写出来，作为参考。  
- [如何看待3月25号开源的旷视深度学习框架天元MegEngine | 知乎](https://www.zhihu.com/question/377416272)  
摘要：要想成为主流，就得解决一个tensorflow和pytorch没能解决的痛点，目前看来国内的情况都不是很乐观。  
- [如何评价清华大学发布的自研深度学习框架-计图(Jittor) | 知乎](https://www.zhihu.com/question/380993685)
摘要：实现了一个比较经典的DAG graph，以及在图上来做fusion和各种pass。从op的实现上，选择了细粒度的op，例如bcast，reduce，等等，然后通过这种方式来形成meta op，比如说convolution：https://github.com/Jittor/jittor/blob/master/notebook/meta_op.src.md  
  1. 值得关注的一点是，在XLA的早期，也有过对于op粒度的探索，目前大家的一些结论是，常见的op，比如说convolution，gemm，如果用细粒度op来实现，然后这些细粒度op是在一个op graph当中来做jit的，对性能会是一个很大的挑战（除了在代码里面embed constant value，loop reordering等等）之外，很多关于计算的细节信息都丢失了，会对后面的fusion pass有很大的挑战。  
  2. 现在一般的自动编译框架选择的方式其实是选择两层IR，一层做计算图DAG，一层做数学表达（比如说bcast，reduce，最典型的是Halide）。可能值得看一看。  
- [如何欣赏一个深度学习框架 | 知乎](https://zhuanlan.zhihu.com/p/117269565)  
摘要：深度学习框架发展到今天，有些功能已经变成常规需求了，譬如易用，高效，完备（算子、模型、配套工具链、文档、案例），一个新的框架在这些方面应该没有明显的短板。一个后出现的框架要追求成功，仅仅没有短板还不够，还必须有长板，独门功法，有超越于其它框架的地方，或者其它框架根本做不到，或者很难做到，只有这样，才有可能先从细分市场切开一个小口，进而站稳脚本。  
- [微信「扫一扫识物」 的背后技术揭秘 | 腾讯技术工程](https://mp.weixin.qq.com/s/fiUUkT7hyJwXmAGQ1kMcqQ)  
摘要：上一期，我们分享了《揭秘微信「扫一扫」识物为什么这么快》这篇文章，本文作为上一篇的前传。  
微信扫码已经深入人心，从识别特定编码形态的图片(二维码/小程序码/条形码/扫翻译)，到精准识别自然场景中商品图片(鞋子/箱包/美妆/服装/家电/玩具/图书/食品/珠宝/家具/其他商品)，有哪些难点需要去克服? 扫物以图片(视频)作为媒介，聚合微信内部有价值的生态内容如电商，百科，资讯进行展示， 会催生哪些新的落地场景?本文将细细道来。  
- [一图理清Nvidia AI软件栈 | StarryHeavensAbove](https://mp.weixin.qq.com/s/aFmr6WKhZ3E-PsF6-uJvJg)  
摘要：CUDA/CUDA-X和相关的软硬件生态，覆盖了AI应用的各个领域，从训练到推理，从数据中心到边缘设备，这种优势的建立并非一日之功。我们在研究AI技术栈的时候，Nvidia无疑是最好的学习对象。大家都在谈论Nvidia的软件生态强大，希望下面这张图能给大家一个更清晰的认识。  
- [手机芯片往事 | 半导体行业观察](https://mp.weixin.qq.com/s/Bge-vxYRdC7UnR--G5x52g)  
摘要：十年之前，小米公司正式成立。一年后，小米手机第一轮开放购买，3小时内10万台库存销售一空。从此，小米开启了它在手机市场上的传奇。2017年，小米自主研发的芯片澎湃S1 搭载小米5c亮相，让小米打开了通往手机芯片的大门。但这扇门所展现的现实却是残酷的，小米5c仅在市场上存在了7个月，我心澎湃至今也没有再起波澜，甚至最近有消息传出，小米已经退出了手机AP芯片的研发。  
手机芯片存在着巨大的市场商机，但要想真正迈进手机芯片这扇门，还需要迈过“人脉”和大笔的“买路财”这两道门槛。或许是因为这门槛又高又宽，在过去十年当中，有不少厂商都在这上面栽了跟头。  
- [当我们在谈论AI芯片时，我们在谈论什么（1）| Simple and Clean](https://mp.weixin.qq.com/s/SC6lGIilYmQeiIhM-0ZmRg)  
摘要：这一系列博客试图谈论AI芯片，尤其是设计中的问题与挑战。也许，更坦率说，是谈论我们应如何展开AI芯片的谈论。
- [当我们在谈论AI芯片时，我们在谈论什么（2）| Simple and Clean](https://mp.weixin.qq.com/s/T4B87uWaMcq6mXEIuuWr7A)  
摘要：燃料不足，引擎失速。上一期的最后提到了访存系统（Memory System）对保持MAC Engine利用率至关重要。也就是说，访存系统是开启神经网络加速计算的关键钥匙。  
内存(Memory)是数据存储的单元。构建一套访存系统需要多种不同种类的内存来执行不同的功能。在处理器内部，访存系统与计算单元进行交互来读取和存储数据。  
通常，访存系统是要为特定类型的计算而定制设计。CPU和GPU有着相当不同的访存系统，一种是为延迟（Latency）敏感计算设计的，另一种是为吞吐（Throughput）敏感计算而设计。因此，要为神经网络计算设计一个好的访存系统，则需要回到源头去研究神经网络内在的数据依赖关系。  
- [苹果A12Z处理器揭秘：A12X打开第八个隐藏GPU核心 | 半导体行业观察](https://mp.weixin.qq.com/s/u5_4g7V-6Rl7hKk54V_j2w)  
摘要：最近发布的iPad Pro 2020款配备了一颗特殊的A12Z处理器，这也是苹果第一次使用“Z”字母作为处理器型号的后缀，那么它和上代iPad Pro使用的A12X有什么不同呢？A12X处理器采用台积电7nm工艺制造，拥有多达100亿个晶体管，集成八核心CPU、七核心GPU、神经网络引擎，每秒运算高达五万亿次，还支持先进的机器学习。  
A12Z其实在芯片层面和A12X是一模一样的，唯一主要区别就是开启了隐藏的第八个GPU核心，也就是拥有八核心CPU、八核心GPU，图形性能因此有所提升。  
另外，A12Z还在A12X的基础上优化了性能控制器，增强了散热架构，CPU核心的频率也有可能更高。  
- [通过vmstat学习CPU和进程性能监控 | 人人都是极客](https://mp.weixin.qq.com/s/y7Iax6jb4Go7g-0gh9JHGw)  
摘要：性能监控和优化是一个庞大而又严谨的体系，要深入研究只能通过原理、实现和工具三方面结合，本文只是管中窥豹学习了CPU调度和进程管理，希望对大家的运维工作有所帮助。虽然文中以Linux Server端为例，但是也同样适用于Android和ARM Linux。  


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)

| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
| - | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】

- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
